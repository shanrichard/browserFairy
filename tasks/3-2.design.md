# Design 3-2

## Requirements

修复NetworkMonitor中的请求重复记录问题，确保每个网络请求只被记录一次，正确处理重定向和多session监听的情况。

### 问题描述
- 同一个requestId出现多次记录（2-4次）
- network.jsonl中sessionId和targetId为null
- 没有处理CDP的重定向事件（redirectResponse）
- 可能存在监听器重复注册

### 影响
- API调用统计数据膨胀2-4倍
- 误导性能分析结果
- 用户误判为网站发送了重复请求

## Solution

### 1. 修复sessionId和targetId记录
```python
# 在NetworkMonitor._on_request_start等方法中
request_data = {
    "sessionId": self.session_id,  # 使用实例的session_id
    "targetId": self.target_id,     # 记录target_id
    # ... 其他字段
}
```

### 2. 处理重定向请求
```python
async def _on_request_start(self, params: dict) -> None:
    # 检查是否为重定向
    if "redirectResponse" in params:
        # 更新现有请求记录，而不是创建新记录
        request_id = params["requestId"]
        if request_id in self.pending_requests:
            self.pending_requests[request_id]["redirects"] = \
                self.pending_requests[request_id].get("redirects", [])
            self.pending_requests[request_id]["redirects"].append({
                "url": params["request"]["url"],
                "status": params["redirectResponse"]["status"],
                "timestamp": params["timestamp"]
            })
        return
    
    # 正常的新请求处理
    # ...
```

### 3. 防止监听器重复注册
```python
class NetworkMonitor:
    def __init__(self):
        self._listeners_registered = False
        self._listener_handlers = {}  # 存储handler引用
    
    async def start_monitoring(self) -> None:
        if self._listeners_registered:
            logger.warning(f"NetworkMonitor listeners already registered for session {self.session_id}")
            return
        
        # 注册监听器并保存引用
        self._listener_handlers["requestWillBeSent"] = self._on_request_start
        self.connector.on_event("Network.requestWillBeSent", self._listener_handlers["requestWillBeSent"])
        # ... 其他监听器
        
        self._listeners_registered = True
```

### 4. 请求去重机制
```python
class NetworkMonitor:
    def __init__(self):
        self._request_cache = {}  # requestId -> last_event_timestamp
        self._cache_ttl = 0.001  # 1ms内的重复事件视为重复
    
    def _is_duplicate_event(self, request_id: str, event_type: str) -> bool:
        cache_key = f"{request_id}:{event_type}"
        now = time.time()
        
        if cache_key in self._request_cache:
            if now - self._request_cache[cache_key] < self._cache_ttl:
                return True
        
        self._request_cache[cache_key] = now
        return False
```

### 5. 添加调试日志
```python
# 在关键位置添加日志
logger.debug(f"Network event: type={event_type}, requestId={request_id}, sessionId={self.session_id}")
```

## Tests

### 单元测试
1. **test_no_duplicate_records**: 验证同一requestId的事件不会被重复记录
2. **test_redirect_handling**: 验证重定向请求被正确合并到原始请求
3. **test_session_id_recorded**: 验证sessionId和targetId被正确记录
4. **test_prevent_duplicate_listeners**: 验证重复调用start_monitoring不会注册多个监听器

### 集成测试
1. 启动监控并访问一个有重定向的网站（如http重定向到https）
2. 验证network.jsonl中：
   - 每个唯一requestId只有一组start/complete记录
   - sessionId和targetId不为null
   - 重定向被标记在同一请求记录中

### 验证方法
```bash
# 统计重复的requestId
jq -r '.requestId' network.jsonl | sort | uniq -c | sort -rn | head

# 检查sessionId是否记录
jq '{requestId, sessionId, targetId}' network.jsonl | head

# 查找重定向
jq 'select(.redirects)' network.jsonl
```

### 预期结果
- requestId重复次数从2-4次降至1次
- 所有记录都有有效的sessionId和targetId
- 重定向请求被正确识别和合并
- API调用统计数据准确反映实际请求数量