# Design 2-3-12 - 实现内存采样分析（HeapProfiler sampling）

## Requirements

基于技术专家评审和用户反馈，实现HeapProfiler采样分析功能，提供轻量级内存分配追踪能力，精确定位内存泄漏源头函数。

### 核心问题

开发同事在实际使用中反馈的关键痛点：
- **内存泄漏源头难定位**：知道内存在增长，但不知道具体是哪个组件或函数导致
- **现有heap监控局限性**：只能看总量变化，无法定位具体分配源头
- **性能分析工具缺失**：需要更细粒度的内存分配分析能力

### 技术专家评审结论

**需求4 - 内存快照分析**的技术可行性分析：
- **定期takeHeapSnapshot不现实**：会严重影响性能，专家不建议
- **替代方案**：`HeapProfiler.startSampling`轻量采样，开销低且实用
- **完整快照改为手动触发**：避免自动化性能影响
- **实现复杂度**：高，需要3-4周实现，属于最复杂功能

### 功能需求

**核心功能**：
1. 轻量级内存分配采样（基于HeapProfiler.startSampling）
2. 函数级内存分配统计和热点识别
3. 调用栈信息收集和解析
4. 按网站维度组织数据，集成到现有数据流

**数据要求**：
- 采样间隔：32768字节（Chrome默认），平衡精度和性能
- 热点函数：top 10内存分配函数，包含函数名、脚本URL、行号
- 调用栈：限制深度≤10层，避免数据过大
- 统计信息：总采样数、节点数、分配总量等汇总数据

**性能要求**：
- 采样开销控制：相对现有监控<10%额外开销
- 数据收集周期：30秒获取一次profile（比内存收集慢6倍）
- 采样重启：每5分钟重启采样，避免数据积累过大
- 优雅降级：HeapProfiler失败不影响其他监控功能

**集成要求**：
- 集成到现有MemoryCollector的综合监控模式
- 通过event_queue机制与其他监控器协作
- 数据通过DataManager写入，按网站维度存储为heap_sampling.jsonl
- 支持现有的频率控制和错误处理机制

### 技术约束

**技术限制**：
1. **API复杂性**：HeapProfiler返回复杂的树形数据结构，需要专门解析
2. **内存开销**：采样数据本身占用内存，需要控制数据积累
3. **调用栈解析**：需要递归遍历调用栈树，计算复杂度较高
4. **Chrome版本兼容性**：确保在不同Chrome版本下工作稳定

**设计原则**：
1. **优雅降级**：如果HeapProfiler启动失败，不影响其他监控功能
2. **性能优先**：采样和数据收集都要有严格的频率控制
3. **原始数据导向**：专注数据收集，复杂分析留给后续AI工具
4. **向下兼容**：不影响现有75%已完成功能的稳定性

### 预期价值

**诊断价值**：
- 精确定位内存泄漏的源头函数
- 发现哪个具体函数/模块在疯狂分配内存
- 实际案例：数据处理函数每次调用分配50MB但未释放
- 不可替代性：现有heap监控只能看总量，无法定位源头

**应用场景**：
- 企业级Web应用内存泄漏诊断
- 大数据处理应用的内存分配优化
- 长期运行应用的内存使用模式分析
- 复杂SPA应用的内存管理问题定位

## Solution

### 技术方案概述

**核心策略**：基于HeapProfiler.startSampling API实现轻量级内存采样，集成到现有MemoryCollector的综合监控架构中，遵循已验证的NetworkMonitor和WebSocket监控集成模式。

### 详细实现设计

#### 1. 采样频率设计方案

**频率控制策略**：
```python
# 核心频率控制参数
HEAP_SAMPLING_INTERVAL = 32768  # bytes, Chrome默认采样间隔
HEAP_PROFILE_COLLECTION_INTERVAL = 30.0  # seconds, 比内存收集慢6倍
HEAP_SAMPLING_DURATION_LIMIT = 300.0  # seconds, 5分钟自动重启采样
HEAP_PROFILE_MAX_NODES = 1000  # 节点数上限，防止数据过大
```

**同步机制**：
- **启动时机**：与MemoryCollector的综合监控同步启动
- **收集周期**：独立于5秒内存收集周期，每30秒收集一次heap profile
- **重启策略**：每5分钟stopSampling→startSampling，防止数据无限积累
- **停止清理**：在MemoryCollector停止时确保正确停止采样

#### 2. 数据格式设计方案

**基于HeapProfiler API数据结构**：
HeapProfiler.getSamplingProfile返回：
- `head`: SamplingHeapProfileNode树的根节点
- `samples`: SamplingHeapProfileSample数组，包含size和nodeId

**存储格式设计**（遵循network.jsonl格式模式）：
```json
{
  "type": "heap_sampling",
  "timestamp": "2025-08-20T14:30:25Z",
  "hostname": "example.com", 
  "sessionId": "session_123",
  "sampling_config": {
    "sampling_interval": 32768,
    "duration_ms": 30000,
    "include_gc_objects": true
  },
  "profile_summary": {
    "total_size": 2048576,
    "total_samples": 256,
    "node_count": 125,
    "max_allocation_size": 65536
  },
  "top_allocators": [
    {
      "function_name": "Array.constructor", 
      "script_url": "https://example.com/app.js",
      "line_number": 145,
      "column_number": 12,
      "self_size": 524288,
      "sample_count": 12,
      "call_stack_depth": 3
    }
  ],
  "event_id": "generated_hash"
}
```

#### 3. 生命周期管理方案

**集成到MemoryCollector综合模式**：
```python
# browserfairy/monitors/memory.py - MemoryCollector类扩展

class MemoryCollector:
    def __init__(self, ...):
        # 现有属性保持不变
        ...
        # 新增heap sampling相关属性
        self.heap_sampling_enabled = False
        self.heap_profile_task: Optional[asyncio.Task] = None
        self.last_heap_restart = 0.0
        
    async def _enable_comprehensive_monitoring(self):
        """Enable comprehensive monitoring with Console, Network, GC, and Heap Sampling."""
        # ... 现有的Console和Network监控代码 ...
        
        # 新增Heap Sampling监控
        if await self._enable_heap_sampling():
            self.heap_sampling_enabled = True
            # 启动独立的heap profile收集任务
            self.heap_profile_task = asyncio.create_task(
                self._heap_profile_collection_loop()
            )
        
    async def _enable_heap_sampling(self) -> bool:
        """启用HeapProfiler采样，返回成功状态"""
        try:
            await self.connector.call("HeapProfiler.enable", session_id=self.session_id)
            await self.connector.call("HeapProfiler.startSampling", {
                "samplingInterval": HEAP_SAMPLING_INTERVAL,
                "includeObjectsCollectedByMajorGC": True
            }, session_id=self.session_id)
            
            self.last_heap_restart = time.time()
            logger.debug(f"Heap sampling enabled for {self.hostname}")
            return True
            
        except Exception as e:
            logger.warning(f"Failed to enable heap sampling: {e}")
            return False
    
    async def _heap_profile_collection_loop(self):
        """独立的heap profile收集循环"""
        while self.running and self.heap_sampling_enabled:
            try:
                await asyncio.sleep(HEAP_PROFILE_COLLECTION_INTERVAL)
                
                # 检查是否需要重启采样（避免数据积累过大）
                if time.time() - self.last_heap_restart > HEAP_SAMPLING_DURATION_LIMIT:
                    await self._restart_heap_sampling()
                
                # 收集当前profile数据
                await self._collect_heap_profile()
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.debug(f"Heap profile collection error: {e}")
                await asyncio.sleep(5.0)  # 错误后等待5秒再重试
```

#### 4. 数据解析方案

**解析策略**（处理HeapProfiler复杂数据结构）：
```python
def _parse_heap_profile(self, profile_data: dict) -> dict:
    """解析HeapProfiler返回的复杂数据结构"""
    head = profile_data.get("head", {})
    samples = profile_data.get("samples", [])
    
    # 1. 构建node_id -> node映射（递归遍历树结构）
    nodes_map = {}
    self._build_nodes_map(head, nodes_map)
    
    # 2. 聚合samples数据，按nodeId分组统计
    allocation_stats = defaultdict(lambda: {"total_size": 0, "sample_count": 0})
    total_size = 0
    
    for sample in samples:
        node_id = sample.get("nodeId")
        size = sample.get("size", 0)
        allocation_stats[node_id]["total_size"] += size
        allocation_stats[node_id]["sample_count"] += 1
        total_size += size
    
    # 3. 提取热点函数（top 10 by allocation size）
    top_allocators = []
    sorted_allocations = sorted(allocation_stats.items(), 
                               key=lambda x: x[1]["total_size"], reverse=True)
    
    for node_id, stats in sorted_allocations[:10]:  # 限制top 10
        if node_id in nodes_map:
            node = nodes_map[node_id]
            call_frame = node.get("callFrame", {})
            
            top_allocators.append({
                "function_name": call_frame.get("functionName", "anonymous"),
                "script_url": call_frame.get("url", "unknown")[:200],  # 截断长URL
                "line_number": call_frame.get("lineNumber", 0),
                "column_number": call_frame.get("columnNumber", 0),
                "self_size": stats["total_size"],
                "sample_count": stats["sample_count"],
                "call_stack_depth": self._calculate_stack_depth(node_id, nodes_map)
            })
    
    return {
        "total_samples": len(samples),
        "node_count": len(nodes_map),
        "total_size": total_size,
        "max_allocation_size": max((s.get("size", 0) for s in samples), default=0),
        "top_allocators": top_allocators
    }

def _build_nodes_map(self, node: dict, nodes_map: dict, depth: int = 0) -> None:
    """递归构建节点映射，限制深度防止栈溢出"""
    if depth > 20:  # 防止过深递归
        return
        
    node_id = node.get("id")
    if node_id is not None:
        nodes_map[node_id] = node
        
    # 递归处理子节点
    for child in node.get("children", []):
        self._build_nodes_map(child, nodes_map, depth + 1)

def _calculate_stack_depth(self, node_id: int, nodes_map: dict) -> int:
    """计算调用栈深度"""
    depth = 0
    current_node = nodes_map.get(node_id)
    
    while current_node and depth < 50:  # 防止无限循环
        parent_found = False
        for other_id, other_node in nodes_map.items():
            if any(child.get("id") == node_id for child in other_node.get("children", [])):
                current_node = other_node
                node_id = other_id
                depth += 1
                parent_found = True
                break
        if not parent_found:
            break
            
    return depth
```

#### 5. DataManager集成

**数据写入集成**（遵循现有模式）：
```python
# 在 browserfairy/data/manager.py 中添加

async def write_heap_sampling_data(self, hostname: str, heap_data: Dict[str, Any]) -> None:
    """Heap sampling数据写入"""
    if not self.running:
        return
    file_path = f"{hostname}/heap_sampling.jsonl"
    await self.data_writer.append_jsonl(file_path, heap_data)
```

### 错误处理和性能策略

**优雅降级机制**：
- HeapProfiler.enable失败 → 记录警告，不影响其他监控
- startSampling失败 → 禁用heap sampling，其他功能正常
- getSamplingProfile超时 → 重启采样，继续尝试
- 数据解析异常 → 记录错误事件，继续下一轮收集

**性能优化策略**：
- **数据限制**：限制节点数≤1000，防止解析开销过大
- **超时控制**：所有CDP调用设置3秒超时
- **内存清理**：每次收集后释放临时数据结构
- **频率控制**：独立收集周期，不增加现有监控频率

**监控影响控制**：
- **CPU开销**：heap profile解析限制在每30秒<100ms
- **内存占用**：临时数据结构及时清理，常驻开销<5MB
- **网络流量**：无额外网络请求，仅本地CDP调用
- **数据存储**：每小时约生成1-2KB数据，影响极小

## Tests

### 测试驱动开发方案

遵循已完成任务的TDD模式，确保功能正确性和稳定性。

#### 1. 单元测试

```python
# tests/test_heap_sampling.py

import pytest
from unittest.mock import AsyncMock, MagicMock
from browserfairy.monitors.memory import MemoryCollector

class TestHeapSampling:
    
    @pytest.fixture
    def memory_collector(self):
        mock_connector = AsyncMock()
        collector = MemoryCollector(
            mock_connector, "test_target", "test.example.com",
            enable_comprehensive=True
        )
        return collector
    
    @pytest.mark.asyncio
    async def test_heap_sampling_initialization(self, memory_collector):
        """测试HeapProfiler采样初始化"""
        # Mock HeapProfiler.enable和startSampling调用
        memory_collector.connector.call.return_value = {}
        
        success = await memory_collector._enable_heap_sampling()
        
        # 验证必要的CDP调用
        calls = memory_collector.connector.call.call_args_list
        assert any("HeapProfiler.enable" in str(call) for call in calls)
        assert any("HeapProfiler.startSampling" in str(call) for call in calls)
        assert success is True
        assert memory_collector.last_heap_restart > 0
    
    def test_heap_profile_data_parsing(self, memory_collector):
        """测试heap profile数据解析"""
        # 构造模拟的HeapProfiler返回数据
        mock_profile = {
            "head": {
                "id": 1,
                "callFrame": {
                    "functionName": "global",
                    "url": "https://example.com/app.js",
                    "lineNumber": 1
                },
                "children": [
                    {
                        "id": 2,
                        "callFrame": {
                            "functionName": "allocateArray",
                            "url": "https://example.com/app.js", 
                            "lineNumber": 45
                        },
                        "children": []
                    }
                ]
            },
            "samples": [
                {"nodeId": 2, "size": 1024},
                {"nodeId": 2, "size": 2048},
                {"nodeId": 1, "size": 512}
            ]
        }
        
        result = memory_collector._parse_heap_profile(mock_profile)
        
        # 验证解析结果
        assert result["total_samples"] == 3
        assert result["total_size"] == 3584
        assert result["node_count"] == 2
        assert len(result["top_allocators"]) == 2
        
        # 验证热点函数排序正确
        top_allocator = result["top_allocators"][0]
        assert top_allocator["function_name"] == "allocateArray"
        assert top_allocator["self_size"] == 3072  # 1024 + 2048
        assert top_allocator["sample_count"] == 2
    
    def test_nodes_map_building(self, memory_collector):
        """测试节点映射构建"""
        head_node = {
            "id": 1,
            "callFrame": {"functionName": "root"},
            "children": [
                {
                    "id": 2, 
                    "callFrame": {"functionName": "child1"},
                    "children": [
                        {"id": 3, "callFrame": {"functionName": "grandchild"}, "children": []}
                    ]
                }
            ]
        }
        
        nodes_map = {}
        memory_collector._build_nodes_map(head_node, nodes_map)
        
        assert len(nodes_map) == 3
        assert nodes_map[1]["callFrame"]["functionName"] == "root"
        assert nodes_map[2]["callFrame"]["functionName"] == "child1"
        assert nodes_map[3]["callFrame"]["functionName"] == "grandchild"
    
    @pytest.mark.asyncio
    async def test_sampling_restart_logic(self, memory_collector):
        """测试采样重启逻辑"""
        memory_collector.last_heap_restart = time.time() - 400  # 超过5分钟
        memory_collector.connector.call.return_value = {}
        
        await memory_collector._restart_heap_sampling()
        
        # 验证stop和start调用
        calls = memory_collector.connector.call.call_args_list
        assert any("HeapProfiler.stopSampling" in str(call) for call in calls)
        assert any("HeapProfiler.startSampling" in str(call) for call in calls)
    
    @pytest.mark.asyncio
    async def test_performance_impact(self, memory_collector):
        """测试性能影响控制"""
        import time
        
        # 构造大量节点的profile数据
        large_profile = {
            "head": {"id": 1, "callFrame": {"functionName": "root"}, "children": []},
            "samples": [{"nodeId": 1, "size": 1024} for _ in range(1000)]
        }
        
        start_time = time.time()
        result = memory_collector._parse_heap_profile(large_profile)
        end_time = time.time()
        
        # 验证解析时间合理（<100ms）
        assert end_time - start_time < 0.1
        assert result["total_samples"] == 1000

    @pytest.mark.asyncio
    async def test_error_handling_graceful_degradation(self, memory_collector):
        """测试错误处理和优雅降级"""
        # Mock HeapProfiler调用失败
        memory_collector.connector.call.side_effect = Exception("CDP call failed")
        
        success = await memory_collector._enable_heap_sampling()
        
        # 验证失败时不崩溃，返回False
        assert success is False
        assert memory_collector.heap_sampling_enabled is False
```

#### 2. 集成测试

```python
@pytest.mark.integration 
class TestHeapSamplingIntegration:
    
    @pytest.mark.asyncio
    async def test_heap_sampling_with_memory_collector(self):
        """集成测试：Heap采样与MemoryCollector的完整集成"""
        # 需要真实Chrome环境测试
        pass
    
    @pytest.mark.asyncio
    async def test_data_writing_integration(self):
        """集成测试：Heap采样数据写入DataManager"""
        # 验证heap_sampling.jsonl文件正确写入
        pass
    
    @pytest.mark.asyncio
    async def test_comprehensive_monitoring_integration(self):
        """集成测试：综合监控模式下所有组件协作"""
        # 验证Console、Network、GC、Heap采样同时工作
        pass
```

### 实现步骤（TDD）

1. **Red**: 编写HeapSampling基础测试用例（失败）
2. **Green**: 实现最简单的_enable_heap_sampling()方法
3. **Red**: 添加数据解析测试（失败）
4. **Green**: 实现_parse_heap_profile()方法
5. **Red**: 添加生命周期管理测试（失败）
6. **Green**: 实现_heap_profile_collection_loop()
7. **Refactor**: 重构并优化数据结构和性能
8. **集成**: 集成到MemoryCollector和DataManager

### 验收标准

**功能验收**：
- [ ] HeapProfiler采样能正确启动和停止
- [ ] profile数据能正确解析出热点函数信息  
- [ ] 数据能正确写入独立的heap_sampling.jsonl文件
- [ ] 与MemoryCollector综合模式正确集成
- [ ] 采样重启机制工作正常

**性能验收**：
- [ ] Heap采样开销<10%（相对于现有监控）
- [ ] profile数据解析时间<100ms
- [ ] 常驻内存增加<5MB
- [ ] 不影响现有监控功能的响应时间

**数据验收**：
- [ ] 热点函数数据格式符合设计规范
- [ ] 调用栈信息完整且深度受控
- [ ] 时间戳与其他监控数据对齐
- [ ] 错误场景优雅降级，不影响其他功能

这个设计通过HeapProfiler.startSampling API提供了一个实用的内存分配追踪方案，避免了完整快照的性能问题，保持了与现有架构的一致性和低侵入性。