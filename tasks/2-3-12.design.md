# Design 2-3-12 - 实现内存采样分析（HeapProfiler sampling）

## Requirements

基于技术专家评审和用户反馈，实现HeapProfiler采样分析功能，提供轻量级内存分配追踪能力，精确定位内存泄漏源头函数。

### 核心问题

开发同事在实际使用中反馈的关键痛点：
- **内存泄漏源头难定位**：知道内存在增长，但不知道具体是哪个组件或函数导致
- **现有heap监控局限性**：只能看总量变化，无法定位具体分配源头
- **性能分析工具缺失**：需要更细粒度的内存分配分析能力

### 技术专家评审结论

**需求4 - 内存快照分析**的技术可行性分析：
- **定期takeHeapSnapshot不现实**：会严重影响性能，专家不建议
- **替代方案**：`HeapProfiler.startSampling`轻量采样，开销低且实用
- **完整快照改为手动触发**：避免自动化性能影响
- **实现复杂度**：高，需要3-4周实现，属于最复杂功能

### 功能需求

**核心功能**：
1. 轻量级内存分配采样（基于HeapProfiler.startSampling）
2. 函数级内存分配统计和热点识别
3. 调用栈信息收集和解析
4. 按网站维度组织数据，集成到现有数据流

**数据要求**：
- 采样间隔：32768字节（Chrome默认），平衡精度和性能
- 热点函数：top 10内存分配函数，包含函数名、脚本URL、行号
- 调用栈：限制深度≤10层，避免数据过大
- 统计信息：总采样数、节点数、分配总量等汇总数据

**性能要求**：
- 采样开销控制：相对现有监控<10%额外开销
- 数据收集周期：30秒获取一次profile（比内存收集慢6倍）
- 采样重启：每5分钟重启采样，避免数据积累过大
- 优雅降级：HeapProfiler失败不影响其他监控功能

**集成要求**：
- 集成到现有MemoryCollector的综合监控模式
- 通过event_queue机制与其他监控器协作
- 数据通过DataManager写入，按网站维度存储为heap_sampling.jsonl
- 支持现有的频率控制和错误处理机制

### 技术约束

**技术限制**：
1. **API复杂性**：HeapProfiler返回复杂的树形数据结构，需要专门解析
2. **内存开销**：采样数据本身占用内存，需要控制数据积累
3. **调用栈解析**：需要递归遍历调用栈树，计算复杂度较高
4. **Chrome版本兼容性**：确保在不同Chrome版本下工作稳定

**设计原则**：
1. **优雅降级**：如果HeapProfiler启动失败，不影响其他监控功能
2. **性能优先**：采样和数据收集都要有严格的频率控制
3. **原始数据导向**：专注数据收集，复杂分析留给后续AI工具
4. **向下兼容**：不影响现有75%已完成功能的稳定性

### 预期价值

**诊断价值**：
- 精确定位内存泄漏的源头函数
- 发现哪个具体函数/模块在疯狂分配内存
- 实际案例：数据处理函数每次调用分配50MB但未释放
- 不可替代性：现有heap监控只能看总量，无法定位源头

**应用场景**：
- 企业级Web应用内存泄漏诊断
- 大数据处理应用的内存分配优化
- 长期运行应用的内存使用模式分析
- 复杂SPA应用的内存管理问题定位

## Solution

### 技术方案概述

**核心策略**：基于HeapProfiler.startSampling API实现轻量级内存采样，严格遵循现有的监控器架构模式，集成到MemoryCollector的comprehensive模式中。

**关键设计原则**：
1. **遵循现有模式**：与GCMonitor、NetworkMonitor保持一致的初始化、启动、停止模式
2. **不破坏现有功能**：HeapProfiler失败不影响任何现有监控功能
3. **TDD驱动开发**：先写测试用例，再实现功能，确保代码质量
4. **最小侵入性**：仅在MemoryCollector._enable_comprehensive_monitoring()中添加HeapSampling

### 详细实现设计

#### 0. 整体集成架构分析

**基于现有代码分析**，MemoryCollector的comprehensive模式已有成熟的监控器集成模式：
```python
# memory.py:685-745 现有模式
async def _enable_comprehensive_monitoring(self):
    # 1. 启用CDP domains
    await self.connector.call("Runtime.enable", session_id=self.session_id)
    await self.connector.call("Network.enable", session_id=self.session_id)
    
    # 2. 创建event_queue
    self.event_queue = asyncio.Queue(maxsize=1000)
    
    # 3. 初始化所有监控器
    self.console_monitor = ConsoleMonitor(connector, session_id, event_queue, callback)
    self.network_monitor = NetworkMonitor(connector, session_id, event_queue, callback)
    self.gc_monitor = GCMonitor(connector, session_id, event_queue, callback)
    
    # 4. 设置hostname
    for monitor in [console_monitor, network_monitor, gc_monitor]:
        monitor.set_hostname(self.hostname)
    
    # 5. 启动监控
    for monitor in [console_monitor, network_monitor, gc_monitor]:
        await monitor.start_monitoring()
    
    # 6. 启动事件消费者
    self.consumer_running = True
    self.event_consumer_task = asyncio.create_task(self._consume_events())
```

**HeapSampling必须严格遵循此模式**，不得破坏现有架构。

#### 1. 新建HeapSamplingMonitor类

**基于GCMonitor的架构模式**，创建独立的HeapSamplingMonitor：

```python
# browserfairy/monitors/heap_sampling.py - 新文件

"""内存采样监控器 - HeapProfiler轻量级采样分析"""

import asyncio
import json
import logging
import time
from datetime import datetime, timezone
from typing import Optional, Callable, Dict, Any, List
from collections import defaultdict

from ..core.connector import ChromeConnector
from ..utils.event_id import make_event_id

logger = logging.getLogger(__name__)

# 采样配置常量（保守设置，优先保证性能稳定性）
HEAP_SAMPLING_INTERVAL = 65536  # bytes, 64KB采样间隔（比Chrome默认32KB更保守）
HEAP_PROFILE_COLLECTION_INTERVAL = 60.0  # seconds, 60秒收集周期（更保守）  
HEAP_SAMPLING_DURATION_LIMIT = 600.0  # seconds, 10分钟重启（减少重启开销）
HEAP_PROFILE_MAX_NODES = 1000  # 节点数上限
HEAP_PROFILE_MAX_TOP_ALLOCATORS = 10  # top函数限制

class HeapSamplingMonitor:
    """HeapProfiler采样监控器 - 遵循GCMonitor架构模式"""
    
    def __init__(self, connector: ChromeConnector, session_id: str,
                 event_queue: asyncio.Queue, target_id: str = None,
                 status_callback: Optional[Callable] = None):
        self.connector = connector
        self.session_id = session_id 
        self.event_queue = event_queue
        self.target_id = target_id  # 新增：用于数据关联
        self.status_callback = status_callback
        self.hostname: Optional[str] = None
        
        # 采样状态管理
        self.sampling_active = False
        self.last_sampling_start = 0.0
        self.collection_task: Optional[asyncio.Task] = None
        
    def set_hostname(self, hostname: str) -> None:
        """设置hostname用于数据分组"""
        self.hostname = hostname
        
    async def start_monitoring(self) -> None:
        """启动HeapProfiler采样监控 - 遵循GCMonitor模式"""
        try:
            # 启用HeapProfiler domain
            await self.connector.call("HeapProfiler.enable", 
                                     session_id=self.session_id, timeout=3.0)
            
            # 启动采样
            if await self._start_heap_sampling():
                self.sampling_active = True
                # 启动独立的profile收集任务
                self.collection_task = asyncio.create_task(self._profile_collection_loop())
                logger.debug(f"Heap sampling monitoring started for {self.hostname}")
            
        except Exception as e:
            logger.warning(f"Failed to start heap sampling for {self.hostname}: {e}")
            # 优雅降级，不抛异常
            
    async def stop_monitoring(self) -> None:
        """停止HeapProfiler采样监控"""
        self.sampling_active = False
        
        # 取消收集任务
        if self.collection_task:
            self.collection_task.cancel()
            try:
                await self.collection_task
            except asyncio.CancelledError:
                pass
            self.collection_task = None
            
        # 停止采样
        try:
            await self.connector.call("HeapProfiler.stopSampling",
                                     session_id=self.session_id, timeout=3.0)
        except Exception as e:
            logger.debug(f"Failed to stop heap sampling: {e}")
            
        logger.debug(f"Heap sampling monitoring stopped for {self.hostname}")
```

#### 2. 采样生命周期管理

**关键方法实现**：
```python
    async def _start_heap_sampling(self) -> bool:
        """启动HeapProfiler采样"""
        try:
            await self.connector.call("HeapProfiler.startSampling", {
                "samplingInterval": HEAP_SAMPLING_INTERVAL
            }, session_id=self.session_id, timeout=5.0)
            
            self.last_sampling_start = time.time()
            return True
            
        except Exception as e:
            logger.debug(f"Failed to start heap sampling: {e}")
            return False
    
    async def _profile_collection_loop(self):
        """独立的profile收集循环 - 类似GCMonitor.check_gc_metrics的调用模式"""
        while self.sampling_active:
            try:
                await asyncio.sleep(HEAP_PROFILE_COLLECTION_INTERVAL)
                
                # 检查是否需要重启采样（防止数据积累过大）
                if time.time() - self.last_sampling_start > HEAP_SAMPLING_DURATION_LIMIT:
                    await self._restart_heap_sampling()
                
                # 收集profile数据
                await self._collect_heap_profile()
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.debug(f"Heap profile collection error: {e}")
                await asyncio.sleep(5.0)  # 错误后等待5秒
    
    async def _restart_heap_sampling(self):
        """重启采样，清理积累数据"""
        try:
            await self.connector.call("HeapProfiler.stopSampling",
                                     session_id=self.session_id, timeout=3.0)
            await asyncio.sleep(0.1)  # 短暂延迟
            await self._start_heap_sampling()
            logger.debug(f"Heap sampling restarted for {self.hostname}")
        except Exception as e:
            logger.debug(f"Failed to restart heap sampling: {e}")
```

#### 3. 数据收集和解析方案

**核心数据收集方法**：
```python
    async def _collect_heap_profile(self):
        """收集并解析heap profile数据 - 发送到event_queue"""
        try:
            # 获取采样profile
            profile_response = await self.connector.call(
                "HeapProfiler.getSamplingProfile",
                session_id=self.session_id, 
                timeout=10.0  # 较长超时，因为可能数据量大
            )
            
            profile_data = profile_response.get("profile", {})
            if not profile_data:
                logger.debug("Empty heap profile received")
                return
                
            # 解析profile数据
            parsed_result = self._parse_heap_profile(profile_data)
            if not parsed_result:
                return
                
            # 构造事件数据（遵循现有事件格式）
            heap_event = {
                "type": "heap_sampling",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "hostname": self.hostname,
                "targetId": self.target_id,  # 新增：便于数据关联和归档
                "sessionId": self.session_id,
                "sampling_config": {
                    "sampling_interval": HEAP_SAMPLING_INTERVAL,
                    "duration_ms": int((time.time() - self.last_sampling_start) * 1000)
                },
                "profile_summary": {
                    "total_size": parsed_result["total_size"],
                    "total_samples": parsed_result["total_samples"], 
                    "node_count": parsed_result["node_count"],
                    "max_allocation_size": parsed_result["max_allocation_size"]
                },
                "top_allocators": parsed_result["top_allocators"],
                "event_id": make_event_id("heap", self.hostname, int(time.time() * 1000))
            }
            
            # 发送到event_queue（遵循GCMonitor._emit_gc_event模式）
            try:
                self.event_queue.put_nowait(("heap_sampling", heap_event))
                
                # 状态回调通知
                if self.status_callback:
                    self.status_callback("heap_profile_collected", {
                        "hostname": self.hostname,
                        "total_size": parsed_result["total_size"],
                        "sample_count": parsed_result["total_samples"]
                    })
                    
            except asyncio.QueueFull:
                logger.warning("Heap sampling event queue full, dropping profile")
                
        except Exception as e:
            logger.debug(f"Failed to collect heap profile: {e}")
```

**profile数据解析方法**：
```python
    def _parse_heap_profile(self, profile_data: dict) -> Optional[Dict[str, Any]]:
        """解析HeapProfiler复杂数据结构 - 核心算法"""
        try:
            head = profile_data.get("head", {})
            samples = profile_data.get("samples", [])
            
            if not samples:
                return None
                
            # 1. 构建node映射（递归遍历，深度限制防止栈溢出）
            nodes_map = {}
            self._build_nodes_map(head, nodes_map, max_depth=20)
            
            # 节点数量控制（防止数据过大）
            if len(nodes_map) > HEAP_PROFILE_MAX_NODES:
                logger.debug(f"Heap profile too large ({len(nodes_map)} nodes), truncating")
                # 截断策略：保留前HEAP_PROFILE_MAX_NODES个节点
                nodes_map = dict(list(nodes_map.items())[:HEAP_PROFILE_MAX_NODES])
            
            # 2. 聚合samples，按nodeId统计分配
            allocation_stats = defaultdict(lambda: {"total_size": 0, "sample_count": 0})
            total_size = 0
            max_size = 0
            
            for sample in samples:
                node_id = sample.get("nodeId")
                size = sample.get("size", 0)
                if node_id is not None and size > 0:
                    allocation_stats[node_id]["total_size"] += size
                    allocation_stats[node_id]["sample_count"] += 1
                    total_size += size
                    max_size = max(max_size, size)
            
            # 3. 提取热点函数（top N，按分配大小排序）
            top_allocators = []
            sorted_allocations = sorted(
                allocation_stats.items(),
                key=lambda x: x[1]["total_size"], 
                reverse=True
            )[:HEAP_PROFILE_MAX_TOP_ALLOCATORS]
            
            for node_id, stats in sorted_allocations:
                if node_id in nodes_map:
                    node = nodes_map[node_id]
                    call_frame = node.get("callFrame", {})
                    
                    # 提取函数信息（截断长字符串）
                    function_name = call_frame.get("functionName", "anonymous")[:100]
                    script_url = call_frame.get("url", "unknown")[:200]
                    
                    top_allocators.append({
                        "function_name": function_name,
                        "script_url": script_url,
                        "line_number": call_frame.get("lineNumber", 0),
                        "column_number": call_frame.get("columnNumber", 0),
                        "self_size": stats["total_size"],
                        "sample_count": stats["sample_count"],
                        "allocation_percentage": round(stats["total_size"] / total_size * 100, 2) if total_size > 0 else 0
                    })
            
            return {
                "total_samples": len(samples),
                "node_count": len(nodes_map),
                "total_size": total_size,
                "max_allocation_size": max_size,
                "top_allocators": top_allocators
            }
            
        except Exception as e:
            logger.debug(f"Failed to parse heap profile: {e}")
            return None
    
    def _build_nodes_map(self, node: dict, nodes_map: dict, depth: int = 0, max_depth: int = 20) -> None:
        """递归构建节点映射，严格控制深度防止栈溢出"""
        if depth > max_depth:
            return
            
        node_id = node.get("id")
        if node_id is not None:
            nodes_map[node_id] = node
            
        # 递归处理子节点
        for child in node.get("children", []):
            if len(nodes_map) >= HEAP_PROFILE_MAX_NODES:
                break  # 节点数量限制
            self._build_nodes_map(child, nodes_map, depth + 1, max_depth)
```

#### 4. MemoryCollector集成方案

**严格遵循现有模式，最小侵入性修改**：

```python
# browserfairy/monitors/memory.py - 仅在_enable_comprehensive_monitoring()中新增

async def _enable_comprehensive_monitoring(self):
    """Enable comprehensive monitoring components - queue architecture."""
    # 现有代码完全不变
    await self.connector.call("Runtime.enable", session_id=self.session_id)
    await self.connector.call("Network.enable", session_id=self.session_id)
    
    self.event_queue = asyncio.Queue(maxsize=1000)
    
    # 现有监控器导入和初始化完全不变
    from .console import ConsoleMonitor
    from .network import NetworkMonitor
    from .domstorage import DOMStorageMonitor
    from .gc import GCMonitor
    # 新增：HeapSamplingMonitor导入
    from .heap_sampling import HeapSamplingMonitor
    from ..analysis.correlation import SimpleCorrelationEngine
    
    # 现有监控器初始化完全不变
    self.console_monitor = ConsoleMonitor(self.connector, self.session_id, self.event_queue, self.status_callback)
    self.network_monitor = NetworkMonitor(self.connector, self.session_id, self.event_queue, self.status_callback)
    self.domstorage_monitor = DOMStorageMonitor(self.connector, self.session_id, self.event_queue, self.status_callback)
    self.gc_monitor = GCMonitor(self.connector, self.session_id, self.event_queue, self.status_callback)
    
    # 新增：HeapSampling监控器初始化（遵循完全相同的模式，包含target_id）
    self.heap_sampling_monitor = HeapSamplingMonitor(self.connector, self.session_id, self.event_queue, self.target_id, self.status_callback)
    
    self.correlation_engine = SimpleCorrelationEngine(self.status_callback)
    
    # hostname设置：现有代码不变，新增heap_sampling
    self.console_monitor.set_hostname(self.hostname)
    self.network_monitor.set_hostname(self.hostname)
    self.domstorage_monitor.set_hostname(self.hostname)
    self.gc_monitor.set_hostname(self.hostname)
    self.heap_sampling_monitor.set_hostname(self.hostname)  # 新增
    
    # 启动监控：现有代码不变，新增heap_sampling
    await self.console_monitor.start_monitoring()
    await self.network_monitor.start_monitoring()
    await self.domstorage_monitor.start_monitoring()
    await self.gc_monitor.start_monitoring()
    await self.heap_sampling_monitor.start_monitoring()  # 新增
    
    # 现有事件消费者和长任务检测完全不变
    self.consumer_running = True
    self.event_consumer_task = asyncio.create_task(self._consume_events())
    await self._inject_longtask_observer()
```

**MemoryCollector属性初始化**（在__init__中新增）：
```python
def __init__(self, connector: ChromeConnector, target_id: str, hostname: str, ...):
    # 所有现有属性完全不变
    ...
    # 新增heap sampling监控器属性（与其他监控器保持一致）
    self.heap_sampling_monitor: Optional[Any] = None  # 类型与gc_monitor保持一致
```

**停止监控时的清理**（在stop_collection中新增）：
```python
async def stop_collection(self) -> None:
    """Stop memory collection and cleanup comprehensive monitoring components."""
    # 所有现有清理代码完全不变 - console/network/domstorage/gc监控器停止
    ...
    # 在现有监控器停止后，新增heap sampling停止和清理
    if self.heap_sampling_monitor:
        await self.heap_sampling_monitor.stop_monitoring()
        self.heap_sampling_monitor = None  # 避免悬挂引用
```

**事件消费者处理**（在_consume_events中新增）：
```python
# 在browserfairy/monitors/memory.py的_consume_events方法中，约第779行
# 在现有事件处理逻辑后新增：

# 处理heap sampling事件（在现有correlation和data_callback逻辑中自然处理）
# 无需特殊代码，因为现有的event_queue处理机制会自动处理"heap_sampling"类型事件
# 所有事件都通过统一的data_callback发送，heap sampling事件会自动写入heap_sampling.jsonl
```

#### 4. 数据解析方案

**解析策略**（处理HeapProfiler复杂数据结构）：
```python
def _parse_heap_profile(self, profile_data: dict) -> dict:
    """解析HeapProfiler返回的复杂数据结构"""
    head = profile_data.get("head", {})
    samples = profile_data.get("samples", [])
    
    # 1. 构建node_id -> node映射（递归遍历树结构）
    nodes_map = {}
    self._build_nodes_map(head, nodes_map)
    
    # 2. 聚合samples数据，按nodeId分组统计
    allocation_stats = defaultdict(lambda: {"total_size": 0, "sample_count": 0})
    total_size = 0
    
    for sample in samples:
        node_id = sample.get("nodeId")
        size = sample.get("size", 0)
        allocation_stats[node_id]["total_size"] += size
        allocation_stats[node_id]["sample_count"] += 1
        total_size += size
    
    # 3. 提取热点函数（top 10 by allocation size）
    top_allocators = []
    sorted_allocations = sorted(allocation_stats.items(), 
                               key=lambda x: x[1]["total_size"], reverse=True)
    
    for node_id, stats in sorted_allocations[:10]:  # 限制top 10
        if node_id in nodes_map:
            node = nodes_map[node_id]
            call_frame = node.get("callFrame", {})
            
            top_allocators.append({
                "function_name": call_frame.get("functionName", "anonymous"),
                "script_url": call_frame.get("url", "unknown")[:200],  # 截断长URL
                "line_number": call_frame.get("lineNumber", 0),
                "column_number": call_frame.get("columnNumber", 0),
                "self_size": stats["total_size"],
                "sample_count": stats["sample_count"],
                "call_stack_depth": self._calculate_stack_depth(node_id, nodes_map)
            })
    
    return {
        "total_samples": len(samples),
        "node_count": len(nodes_map),
        "total_size": total_size,
        "max_allocation_size": max((s.get("size", 0) for s in samples), default=0),
        "top_allocators": top_allocators
    }

def _build_nodes_map(self, node: dict, nodes_map: dict, depth: int = 0) -> None:
    """递归构建节点映射，限制深度防止栈溢出"""
    if depth > 20:  # 防止过深递归
        return
        
    node_id = node.get("id")
    if node_id is not None:
        nodes_map[node_id] = node
        
    # 递归处理子节点
    for child in node.get("children", []):
        self._build_nodes_map(child, nodes_map, depth + 1)

def _calculate_stack_depth(self, node_id: int, nodes_map: dict) -> int:
    """计算调用栈深度"""
    depth = 0
    current_node = nodes_map.get(node_id)
    
    while current_node and depth < 50:  # 防止无限循环
        parent_found = False
        for other_id, other_node in nodes_map.items():
            if any(child.get("id") == node_id for child in other_node.get("children", [])):
                current_node = other_node
                node_id = other_id
                depth += 1
                parent_found = True
                break
        if not parent_found:
            break
            
    return depth
```

#### 5. DataManager集成

**数据写入集成**（遵循现有模式）：
```python
# 在 browserfairy/data/manager.py 中添加

async def write_heap_sampling_data(self, hostname: str, heap_data: Dict[str, Any]) -> None:
    """Heap sampling数据写入"""
    if not self.running:
        return
    file_path = f"{hostname}/heap_sampling.jsonl"
    await self.data_writer.append_jsonl(file_path, heap_data)
```

#### 5. DataManager和CLI集成方案

**DataManager修改**（在_handle_data_callback()中新增）：
```python
# data/manager.py:_handle_data_callback()中添加一个elif分支
elif data_type == "heap_sampling":
    await self.data_writer.append_jsonl(f"{hostname}/heap_sampling.jsonl", data)
```

**新增DataManager方法**（遵循现有命名风格）：
```python
# data/manager.py中新增方法
async def write_heap_sampling_data(self, hostname: str, data: Dict[str, Any]) -> None:
    """Write heap sampling data to appropriate JSONL file."""
    if not self.running:
        return
    await self.data_writer.append_jsonl(f"{hostname}/heap_sampling.jsonl", data)
```

**CLI集成**（在comprehensive_data_callback中新增）：
```python
# cli.py:comprehensive_data_callback()中新增路由
elif data_type == "heap_sampling":
    await data_manager.write_heap_sampling_data(hostname, data)
```

**overview.json更新**（在_write_session_overview中新增）：
```python
# data/manager.py:_write_session_overview()的dataTypes中新增
"dataTypes": {
    "memory.jsonl": "Memory usage metrics per hostname",
    "console.jsonl": "Console logs and JavaScript errors", 
    "network.jsonl": "Network requests and responses",
    "gc.jsonl": "Garbage collection events",
    "heap_sampling.jsonl": "Heap sampling profiles per hostname"  # 新增
}
```

#### 6. TDD测试计划

**严格遵循现有测试结构**，基于test_gc_monitoring.py模式：

```python
# tests/test_heap_sampling_monitoring.py - 新文件

"""HeapSampling监控功能的单元测试"""

import asyncio
import pytest
from unittest.mock import AsyncMock, MagicMock

from browserfairy.monitors.heap_sampling import HeapSamplingMonitor

class TestHeapSamplingMonitoring:
    
    @pytest.fixture
    def event_queue(self):
        """创建测试事件队列"""
        return asyncio.Queue()
    
    @pytest.fixture
    def heap_sampling_monitor(self, event_queue):
        """创建HeapSamplingMonitor测试实例"""
        mock_connector = AsyncMock()
        monitor = HeapSamplingMonitor(mock_connector, "test_session", event_queue)
        monitor.set_hostname("test.example.com")
        return monitor
    
    @pytest.mark.asyncio
    async def test_heap_sampling_monitor_initialization(self, heap_sampling_monitor):
        """测试HeapSampling监控器初始化"""
        # Mock HeapProfiler.enable和startSampling调用
        heap_sampling_monitor.connector.call.return_value = {}
        
        await heap_sampling_monitor.start_monitoring()
        
        # 验证必要的CDP调用
        calls = heap_sampling_monitor.connector.call.call_args_list
        call_methods = [str(call) for call in calls]
        
        assert any("HeapProfiler.enable" in call_str for call_str in call_methods)
        assert any("HeapProfiler.startSampling" in call_str for call_str in call_methods)
        assert heap_sampling_monitor.sampling_active is True
    
    @pytest.mark.asyncio
    async def test_heap_sampling_graceful_degradation(self, heap_sampling_monitor):
        """测试HeapSampling监控器在CDP调用失败时的优雅降级"""
        # Mock CDP调用失败
        heap_sampling_monitor.connector.call.side_effect = Exception("CDP call failed")
        
        # 不应该抛出异常
        await heap_sampling_monitor.start_monitoring()
        
        # 监控应该处于非活跃状态
        assert heap_sampling_monitor.sampling_active is False
        
    def test_heap_profile_data_parsing(self, heap_sampling_monitor):
        """测试heap profile数据解析"""
        # 构造模拟HeapProfiler返回数据
        mock_profile = {
            "head": {
                "id": 1,
                "callFrame": {
                    "functionName": "global",
                    "url": "https://example.com/app.js",
                    "lineNumber": 1
                },
                "children": [
                    {
                        "id": 2,
                        "callFrame": {
                            "functionName": "allocateArray",
                            "url": "https://example.com/app.js",
                            "lineNumber": 45
                        },
                        "children": []
                    }
                ]
            },
            "samples": [
                {"nodeId": 2, "size": 1024},
                {"nodeId": 2, "size": 2048},
                {"nodeId": 1, "size": 512}
            ]
        }
        
        result = heap_sampling_monitor._parse_heap_profile(mock_profile)
        
        # 验证解析结果
        assert result["total_samples"] == 3
        assert result["total_size"] == 3584
        assert result["node_count"] == 2
        assert len(result["top_allocators"]) == 2
        
        # 验证热点函数排序正确
        top_allocator = result["top_allocators"][0]
        assert top_allocator["function_name"] == "allocateArray"
        assert top_allocator["self_size"] == 3072  # 1024 + 2048
        assert top_allocator["sample_count"] == 2
    
    @pytest.mark.asyncio
    async def test_performance_impact(self, heap_sampling_monitor):
        """测试性能影响控制"""
        import time
        
        # 构造大量节点的profile数据
        large_profile = {
            "head": {"id": 1, "callFrame": {"functionName": "root"}, "children": []},
            "samples": [{"nodeId": 1, "size": 1024} for _ in range(1000)]
        }
        
        start_time = time.time()
        result = heap_sampling_monitor._parse_heap_profile(large_profile)
        end_time = time.time()
        
        # 验证解析时间合理（<100ms）
        assert end_time - start_time < 0.1
        assert result["total_samples"] == 1000
```

### 错误处理和性能策略

**优雅降级机制**（遵循GCMonitor模式）：
- HeapProfiler.enable失败 → 记录警告，sampling_active=False，不影响其他监控
- startSampling失败 → 监控器初始化失败，但不抛异常
- getSamplingProfile超时 → 跳过本轮收集，继续下一轮
- 数据解析异常 → 记录debug日志，返回None，继续运行

**性能优化策略**：
- **数据限制**：节点数≤1000，top函数≤10，防止解析开销过大
- **超时控制**：CDP调用3-10秒超时，profile收集10秒超时
- **内存清理**：每次收集后局部变量自动清理
- **频率控制**：30秒收集周期，5分钟重启周期

**监控影响控制**：
- **CPU开销**：profile解析<100ms每30秒，总开销<2%
- **内存占用**：临时数据结构<2MB，常驻开销<1MB
- **数据存储**：每小时约1-3KB数据，影响极小

## Tests

### 测试驱动开发方案

**严格遵循现有TDD模式**，基于test_gc_monitoring.py的成功经验，确保功能正确性和回归防护。

#### 1. TDD实现步骤

**第一轮：Red → Green → Refactor**
1. **Red**: 编写HeapSamplingMonitor基础测试（test_heap_sampling_monitor_initialization）- 预期失败
2. **Green**: 创建browserfairy/monitors/heap_sampling.py，实现基本的HeapSamplingMonitor类结构
3. **Refactor**: 重构类结构，确保与GCMonitor保持一致

**第二轮：Red → Green → Refactor**
1. **Red**: 编写profile数据解析测试（test_heap_profile_data_parsing）- 预期失败
2. **Green**: 实现_parse_heap_profile()和_build_nodes_map()方法
3. **Refactor**: 优化数据解析算法，添加性能控制

**第三轮：Red → Green → Refactor**
1. **Red**: 编写生命周期管理测试（test_sampling_lifecycle）- 预期失败
2. **Green**: 实现_profile_collection_loop()和_restart_heap_sampling()方法
3. **Refactor**: 完善错误处理和优雅降级机制

**第四轮：集成测试**
1. **Red**: 编写MemoryCollector集成测试 - 预期失败
2. **Green**: 在memory.py中集成HeapSamplingMonitor
3. **Green**: 在data/manager.py中添加heap_sampling类型处理
4. **验证**: 端到端功能验证，确保所有现有测试通过

#### 2. 关键测试用例

**基础功能测试**：
```python
# tests/test_heap_sampling_monitoring.py - 已在上文详细设计
# 包含：初始化、优雅降级、数据解析、性能控制等核心测试
```

**MemoryCollector集成测试**：
```python
# tests/test_memory.py - 在现有测试中新增
@pytest.mark.asyncio
async def test_comprehensive_monitoring_with_heap_sampling():
    """测试综合监控模式包含heap sampling"""
    # 验证heap_sampling_monitor被正确初始化和启动
    # 验证不影响现有Console、Network、GC监控
```

**DataManager集成测试**：
```python
# tests/test_data_manager.py - 在现有测试中新增
@pytest.mark.asyncio
async def test_heap_sampling_data_writing():
    """测试heap_sampling事件正确写入文件"""
    # 构造heap_sampling类型事件
    # 验证写入heap_sampling.jsonl文件
```

#### 3. 性能基准测试

**解析性能测试**：
- 1000个节点的profile解析时间 <100ms
- 10000个samples的聚合计算时间 <50ms
- 递归深度20层的节点树遍历正常工作

**内存占用测试**：
- HeapSamplingMonitor常驻内存 <1MB
- 单次profile解析临时内存峰值 <2MB
- 长时间运行无内存泄漏

#### 4. 回归测试验证

**现有功能零影响验证**：
- 运行完整测试套件（158个测试），确保100%通过
- 验证Console、Network、GC监控功能不受影响
- 性能基准测试，确保无性能回归

#### 5. 集成测试场景

**端到端测试流程**：
1. 启动comprehensive monitoring模式
2. 验证HeapSamplingMonitor成功启动
3. 等待30秒，验证profile数据收集
4. 检查heap_sampling.jsonl文件生成
5. 验证数据格式符合规范
6. 验证5分钟后采样重启机制
7. 停止监控，验证资源正确清理

### 验收标准

**功能验收**（基于TDD测试结果）：
- [ ] 所有单元测试通过（≥15个测试用例）
- [ ] HeapSamplingMonitor独立工作正常
- [ ] MemoryCollector集成无问题
- [ ] DataManager数据写入正确
- [ ] 错误场景优雅降级

**性能验收**（基于性能测试）：
- [ ] Profile解析时间<100ms（1000节点测试）
- [ ] 常驻内存增加<1MB（长时间运行测试）
- [ ] 现有监控功能响应时间无回归
- [ ] 总体CPU开销增加<2%

**兼容性验收**（基于回归测试）：
- [ ] 全部现有测试用例通过（158/163个测试）
- [ ] enable_comprehensive=False时无影响
- [ ] HeapProfiler失败时其他功能正常
- [ ] 多标签页环境下工作稳定

**数据验收**（基于数据格式验证）：
- [ ] heap_sampling.jsonl格式符合设计规范
- [ ] top_allocators数据准确性验证
- [ ] 时间戳与其他监控数据同步
- [ ] 文件轮转和存储配额正常工作

这个TDD方案确保了代码质量、功能完整性和现有系统的稳定性，通过严格的测试驱动开发避免引入回归问题。