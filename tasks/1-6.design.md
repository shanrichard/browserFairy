# Design 1-6 - 多指标整合收集器（精准问题定位）

## Requirements

### 核心目标
- **精准问题定位**：从代码级别追踪性能问题根源
- **Console日志监控**：捕获所有级别的控制台输出，包括性能标记
- **Network请求详细追踪**：API调用的完整生命周期和调用栈信息
- **JavaScript执行监控**：长任务、异常、内存分配的函数级追踪
- **跨层关联分析**：网络请求→JS执行→内存变化→Console日志的完整链路

### 精准监控需求
**Console日志监控**：
- 分级日志收集：console.log/warn/error/debug的完整内容和上下文
- 性能标记追踪：console.time/timeEnd的执行耗时统计
- 错误堆栈完整信息：JavaScript异常的详细调用栈
- 自定义埋点支持：应用代码中的性能标记和调试信息

**Network请求精准追踪**：
- 完整请求生命周期：URL、方法、头部、请求体、响应体
- 调用栈关联：网络请求的JavaScript发起位置和函数调用链
- 大数据请求特别标记：>1MB的请求响应（针对5.2M JSON问题）
- API性能深度分析：响应时间、失败重试、缓存行为

**JavaScript执行深度监控**：
- 长任务检测：>50ms的函数执行，包含具体函数名和调用栈
- 内存分配追踪：哪个函数/操作分配了大量内存
- 垃圾回收关联：GC事件与具体代码执行的时间关联
- 异常上下文捕获：运行时错误的详细变量状态和执行环境

## Solution

### ⚠️ 专家评审问题修正

**承认设计问题**：经技术专家评审，原设计存在以下致命问题：
1. **事件订阅API不匹配**：现有ChromeConnector不支持按sessionId区分事件
2. **过度承诺功能**：CDP无法直接获取完整请求体/响应体和函数级长任务信息  
3. **背压问题**：事件处理器直接await会阻塞接收循环
4. **缺乏事件量控制**：未考虑高频事件对系统的冲击

**修正策略**：降低复杂度，聚焦可实现目标，采用现实的技术方案。

### 修正后的设计原则

**现实可行原则**：
- 使用现有ChromeConnector API，手动过滤sessionId
- 仅做元数据级监控，不抓取完整body
- 简化关联分析，避免复杂推断

**性能优先原则**：
- 异步队列解耦事件接收和处理
- 事件量控制和消息限长
- 最小化监控开销

**TDD驱动**（保持不变）：
- 先写测试，明确预期行为
- 每个组件独立测试，便于调试
- 集成测试验证完整链路

### 核心架构设计

**修正后的架构（现实可行版本）**：
```
ChromeConnector (现有API) + TabMonitor (1-3) + DataManager (1-5)
    ↓ 现有on_event/off_event机制
MemoryCollector (1-4) → 添加可选comprehensive模式 + 异步队列
    ├── EventQueue (asyncio.Queue) - 解耦事件接收和处理
    ├── ConsoleMonitor - 手动sessionId过滤 + 消息限长
    ├── NetworkMonitor - 元数据级监控，无body抓取  
    └── SimpleCorrelationEngine - 简化时间窗口关联
```

**修正后的数据流**：
```
CDP Events → 现有事件机制 → 手动sessionId过滤 → 异步队列 → 批量处理 → JSONL文件
                ↓ 避免阻塞接收循环        ↓ 事件量控制
```

**约束条件**：
- 同一时刻仅attach少量标签页（≤5个）
- 事件频率控制：Console ≤10/s，Network ≤50/s
- 消息长度限制：≤500字符
- 队列容量限制：1000事件，满时丢弃

### 核心类设计

**唯一方案: ChromeConnector sessionId注入修正（必须实施）**

这是**唯一可行方案**，必须在 `browserfairy/core/connector.py` 的 `_handle_messages` 方法中实施：

```python
# browserfairy/core/connector.py - 第147-170行修正
async def _handle_messages(self) -> None:
    """Handle incoming WebSocket messages."""
    try:
        async for message in self.websocket:
            try:
                data = json.loads(message)
                
                # Handle responses (messages with id)
                if "id" in data:
                    request_id = data["id"]
                    future = self.pending_requests.pop(request_id, None)
                    
                    if future and not future.done():
                        if "error" in data:
                            error_msg = data["error"].get("message", "Unknown error")
                            future.set_exception(ChromeConnectionError(error_msg))
                        else:
                            future.set_result(data.get("result", {}))
                
                # Handle events (messages without id) - 唯一修正点
                elif "method" in data:
                    method = data["method"]
                    params = data.get("params", {}).copy()
                    
                    # ✅ 唯一方案：注入sessionId到params
                    if "sessionId" in data:
                        params["sessionId"] = data["sessionId"]
                    
                    await self._dispatch_event(method, params)
                    
            except json.JSONDecodeError:
                logger.warning("Received invalid JSON message")
            except Exception as e:
                logger.warning(f"Error handling message: {e}")
                
    except websockets.exceptions.ConnectionClosed:
        logger.info("WebSocket connection closed")
        if self.connection_lost_callback:
            try:
                if asyncio.iscoroutinefunction(self.connection_lost_callback):
                    await self.connection_lost_callback()
                else:
                    self.connection_lost_callback()
            except Exception as e:
                logger.warning(f"Error in connection lost callback: {e}")
    except Exception as e:
        logger.error(f"Error in message handler: {e}")
        if self.connection_lost_callback:
            try:
                if asyncio.iscoroutinefunction(self.connection_lost_callback):
                    await self.connection_lost_callback()
                else:
                    self.connection_lost_callback()
            except Exception as cb_error:
                logger.warning(f"Error in connection lost callback: {cb_error}")
```

**关键修正**：在第115-116行添加sessionId注入，这样Console/Network监控中的 `params.get("sessionId")` 过滤才能工作。

**1. MemoryCollector类扩展（修正版）**
```python
class MemoryCollector:  # 现有类扩展
    def __init__(self, connector: ChromeConnector, target_id: str, hostname: str,
                 data_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
                 enable_comprehensive: bool = False,
                 status_callback: Optional[Callable] = None):
        # 保持现有参数不变
        self.connector = connector
        self.target_id = target_id
        self.hostname = hostname
        self.data_callback = data_callback
        self.session_id: Optional[str] = None
        
        # 新增可选参数
        self.enable_comprehensive = enable_comprehensive
        self.status_callback = status_callback
        
        # 新增组件（仅在comprehensive模式下初始化）
        self.event_queue: Optional[asyncio.Queue] = None
        self.console_monitor: Optional[ConsoleMonitor] = None
        self.network_monitor: Optional[NetworkMonitor] = None
        self.correlation_engine: Optional[SimpleCorrelationEngine] = None
        self.event_consumer_task: Optional[asyncio.Task] = None
        
    async def attach(self) -> None:
        """建立Target会话（保持现有逻辑）"""
        response = await self.connector.call(
            "Target.attachToTarget",
            {"targetId": self.target_id, "flatten": True}
        )
        self.session_id = response["sessionId"]
        
        # Performance.enable（现有逻辑保持不变）
        try:
            await self.connector.call("Performance.enable", session_id=self.session_id)
        except Exception:
            pass
            
        # 新增：如果启用综合监控，初始化队列架构
        if self.enable_comprehensive:
            await self._enable_comprehensive_monitoring()
            
        logger.debug(f"Attached to target {self.target_id} with session {self.session_id}")
        
        # 状态回调通知
        if self.status_callback:
            self.status_callback("site_discovered", {
                "hostname": self.hostname,
                "target_id": self.target_id
            })
    
    async def _enable_comprehensive_monitoring(self):
        """启用综合监控组件（修正版 - 队列架构）"""
        # 启用必要的CDP domains
        await self.connector.call("Runtime.enable", session_id=self.session_id)
        await self.connector.call("Network.enable", session_id=self.session_id)
        
        # 创建事件队列（容量限制1000，满时丢弃）
        self.event_queue = asyncio.Queue(maxsize=1000)
        
        # 初始化监控组件（修正构造参数）
        self.console_monitor = ConsoleMonitor(
            self.connector, 
            self.session_id, 
            self.event_queue,  # 修正：添加缺失的event_queue参数
            self.status_callback
        )
        self.network_monitor = NetworkMonitor(
            self.connector, 
            self.session_id, 
            self.event_queue,  # 修正：添加缺失的event_queue参数
            self.status_callback
        )
        self.correlation_engine = SimpleCorrelationEngine(self.status_callback)
        
        # ✅ 修正：设置hostname用于数据分组
        self.console_monitor.set_hostname(self.hostname)
        self.network_monitor.set_hostname(self.hostname)
        
        # 启动监控（使用队列模式，不使用data_callback）
        await self.console_monitor.start_monitoring()
        await self.network_monitor.start_monitoring()
        
        # 启动事件消费者（修正：实现缺失的队列消费者）
        self.event_consumer_task = asyncio.create_task(self._consume_events())
        
    async def _consume_events(self):
        """事件消费者协程（修正版 - 正确的停止条件和生命周期管理）"""
        try:
            while self.running and self.enable_comprehensive:  # ✅ 修正：正确的停止条件
                try:
                    # 批量处理事件（避免单个事件阻塞）
                    events_batch = []
                    timeout = 0.1  # 100ms批量窗口
                    
                    # 收集一批事件
                    try:
                        # 至少等待一个事件
                        event_type, event_data = await asyncio.wait_for(
                            self.event_queue.get(), timeout=1.0
                        )
                        events_batch.append((event_type, event_data))
                        
                        # 尝试收集更多事件（非阻塞）
                        end_time = asyncio.get_event_loop().time() + timeout
                        while (asyncio.get_event_loop().time() < end_time and 
                               len(events_batch) < 50):  # 限制批次大小
                            try:
                                event_type, event_data = self.event_queue.get_nowait()
                                events_batch.append((event_type, event_data))
                            except asyncio.QueueEmpty:
                                break
                                
                    except asyncio.TimeoutError:
                        continue  # 无事件时继续循环
                    
                    # 处理批次事件
                    for event_type, event_data in events_batch:
                        try:
                            # 关联分析
                            correlation_result = None
                            if self.correlation_engine:
                                correlation_result = self.correlation_engine.add_event(event_data)
                            
                            # 发送原始数据到上层回调
                            if self.data_callback:
                                if asyncio.iscoroutinefunction(self.data_callback):
                                    await self.data_callback(event_data)
                                else:
                                    self.data_callback(event_data)
                            
                            # 发送关联结果（如有）
                            if correlation_result and self.data_callback:
                                if asyncio.iscoroutinefunction(self.data_callback):
                                    await self.data_callback(correlation_result)
                                else:
                                    self.data_callback(correlation_result)
                                    
                        except Exception as e:
                            logger.warning(f"Error processing event {event_type}: {e}")
                            
                except Exception as e:
                    logger.error(f"Error in event consumer: {e}")
                    await asyncio.sleep(0.1)  # 避免紧密循环
                    
        except asyncio.CancelledError:
            logger.debug("Event consumer task cancelled")
            raise  # 重新抛出让任务正确取消
        except Exception as e:
            logger.error(f"Fatal error in event consumer: {e}")
            
    async def stop_collection(self) -> None:
        """停止收集和清理（修正版 - 完整的生命周期管理）"""
        self.running = False
        self.enable_comprehensive = False  # ✅ 修正：确保事件消费者能停止
        
        # ✅ 修正：专家要求的完整清理
        if self.console_monitor:
            await self.console_monitor.stop_monitoring()
            
        if self.network_monitor:
            await self.network_monitor.stop_monitoring()
        
        # ✅ 修正：取消并等待事件消费者任务完成
        if self.event_consumer_task:
            self.event_consumer_task.cancel()
            try:
                await self.event_consumer_task
            except asyncio.CancelledError:
                pass
            self.event_consumer_task = None
        
        # 调用父类的停止逻辑
        if self.collection_task:
            self.collection_task.cancel()
            try:
                await self.collection_task
            except asyncio.CancelledError:
                pass
            self.collection_task = None
        
        # 确保Target.detachFromTarget清理
        await self.detach()
```

**2. ConsoleMonitor类（修正版 - 纯队列，统一方法名）**
```python
class ConsoleMonitor:
    """Console日志监控器 - 纯队列模式，无data_callback混杂"""
    
    def __init__(self, connector: ChromeConnector, session_id: str,
                 event_queue: asyncio.Queue, status_callback: Optional[Callable] = None):
        self.connector = connector
        self.session_id = session_id
        self.event_queue = event_queue
        self.status_callback = status_callback
        self.limiter = EventLimiter()
        self.hostname = None
        
    def set_hostname(self, hostname: str):
        """设置hostname（用于数据分组）"""
        self.hostname = hostname
        
    async def start_monitoring(self) -> None:
        """启动Console事件监听"""
        self.connector.on_event("Runtime.consoleAPICalled", self._on_console_message)
        self.connector.on_event("Runtime.exceptionThrown", self._on_exception_thrown)
    
    async def stop_monitoring(self) -> None:
        """停止Console事件监听（成对off_event）"""
        self.connector.off_event("Runtime.consoleAPICalled", self._on_console_message)
        self.connector.off_event("Runtime.exceptionThrown", self._on_exception_thrown)
        
    async def _on_console_message(self, params: dict) -> None:
        """处理console消息 - 纯队列路径：过滤→限速→构造→入队"""
        # sessionId过滤
        if params.get("sessionId") != self.session_id:
            return
            
        # 事件频率控制
        if not self.limiter.should_process_console():
            return
            
        # 构建轻量级事件数据
        console_data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "type": "console",
            "level": params["type"],
            "message": self._extract_and_truncate_message(params.get("args", [])),
            "source": self._extract_source(params),
            "hostname": self.hostname
        }
        
        # 唯一出口：入队处理（满时丢弃）
        try:
            self.event_queue.put_nowait(("console", console_data))
        except asyncio.QueueFull:
            logger.warning("Console event queue full, dropping event")
            
        # 状态回调（仅重要事件，非阻塞）
        if params["type"] in ["error", "warn"] and self.status_callback:
            try:
                self.status_callback("console_error", {
                    "level": params["type"],
                    "message": console_data["message"][:50],
                    "source": console_data["source"].get("function", "unknown")
                })
            except Exception as e:
                logger.warning(f"Error in console status callback: {e}")
    
    async def _on_exception_thrown(self, params: dict) -> None:
        """处理JavaScript异常 - 纯队列路径：过滤→构造→入队"""
        # sessionId过滤
        if params.get("sessionId") != self.session_id:
            return
            
        exception = params["exceptionDetails"]
        exception_data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "type": "exception",
            "message": exception["text"][:500],
            "source": {
                "url": exception.get("url", "")[:200],
                "line": exception.get("lineNumber", 0),
                "column": exception.get("columnNumber", 0)
            },
            "stackTrace": self._format_stack_trace(exception.get("stackTrace", {})),
            "hostname": self.hostname
        }
        
        # 唯一出口：入队处理
        try:
            self.event_queue.put_nowait(("exception", exception_data))
        except asyncio.QueueFull:
            logger.warning("Exception event queue full, dropping event")
        
        # 状态回调通知
        if self.status_callback:
            try:
                self.status_callback("console_error", {
                    "level": "exception",
                    "message": exception_data["message"][:50],
                    "source": exception_data["source"]["url"][:30]
                })
            except Exception as e:
                logger.warning(f"Error in exception status callback: {e}")
    
    def _extract_and_truncate_message(self, args: list, max_length: int = 500) -> str:
        """统一方法：从console参数中提取并限制消息长度≤500字符"""
        messages = []
        for arg in args:
            if arg.get("type") == "string":
                messages.append(arg.get("value", ""))
            elif arg.get("type") == "object":
                messages.append(str(arg.get("description", arg.get("value", ""))))
            else:
                messages.append(str(arg.get("value", "")))
        
        full_message = " ".join(messages)
        if len(full_message) <= max_length:
            return full_message
        return full_message[:max_length] + "...[truncated]"
    
    def _extract_source(self, params: dict) -> dict:
        """提取调用源信息"""
        stack = params.get("stackTrace", {})
        if stack and stack.get("callFrames"):
            frame = stack["callFrames"][0]
            return {
                "url": frame.get("url", "")[:200],
                "line": frame.get("lineNumber", 0),
                "function": frame.get("functionName", "anonymous")[:100]
            }
        return {"url": "", "line": 0, "function": "unknown"}
    
    def _format_stack_trace(self, stack: dict) -> list:
        """格式化堆栈信息（限制深度至5层）"""
        if not stack or not stack.get("callFrames"):
            return []
        
        return [
            {
                "function": frame.get("functionName", "anonymous")[:100],
                "url": frame.get("url", "")[:200],
                "line": frame.get("lineNumber", 0),
                "column": frame.get("columnNumber", 0)
            }
            for frame in stack["callFrames"][:5]
        ]
```

class EventLimiter:
    """事件频率限制器（修正版 - 专家建议的简单滑动窗口）"""
    
    def __init__(self):
        self.console_count = 0
        self.network_count = 0
        self.last_reset = time.time()
        self.max_console_per_second = 10  # Console事件限制
        self.max_network_per_second = 50  # Network事件限制
        
        # ✅ 修正：添加丢弃计数（专家建议的排障信息）
        self.console_dropped_count = 0
        self.network_dropped_count = 0
        self.last_dropped_summary = {}
        
    def should_process_console(self) -> bool:
        """检查是否应该处理console事件（专家要求的必需实现）"""
        self._reset_counters()
        if self.console_count >= self.max_console_per_second:
            self.console_dropped_count += 1
            self._update_dropped_summary("console")
            return False
        self.console_count += 1
        return True
        
    def should_process_network(self) -> bool:
        """检查是否应该处理network事件（专家要求的必需实现）"""
        self._reset_counters()
        if self.network_count >= self.max_network_per_second:
            self.network_dropped_count += 1
            self._update_dropped_summary("network")
            return False
        self.network_count += 1
        return True
        
    def _reset_counters(self):
        """重置计数器（每秒一次滑动窗口）"""
        now = time.time()
        if now - self.last_reset >= 1.0:
            # 记录重置前的丢弃统计
            if self.console_dropped_count > 0 or self.network_dropped_count > 0:
                logger.debug(f"Event limiter stats: console_dropped={self.console_dropped_count}, "
                           f"network_dropped={self.network_dropped_count}")
            
            self.console_count = 0
            self.network_count = 0
            self.console_dropped_count = 0
            self.network_dropped_count = 0
            self.last_reset = now
    
    def _update_dropped_summary(self, event_type: str):
        """更新丢弃事件摘要（用于排障）"""
        now = time.time()
        if now - self.last_dropped_summary.get(event_type, 0) > 5.0:  # 5秒间隔记录
            logger.warning(f"Dropping {event_type} events due to rate limiting")
            self.last_dropped_summary[event_type] = now
```

**3. NetworkMonitor类（修正版 - 纯队列，无data_callback混杂）**
```python
class NetworkMonitor:
    """网络请求监控器 - 纯队列模式，统一为过滤→限速→构造→入队"""
    
    def __init__(self, connector: ChromeConnector, session_id: str,
                 event_queue: asyncio.Queue, status_callback: Optional[Callable] = None):
        self.connector = connector
        self.session_id = session_id
        self.event_queue = event_queue
        self.status_callback = status_callback
        self.pending_requests: dict = {}  # requestId -> request metadata
        self.limiter = EventLimiter()
        self.hostname = None
        
    def set_hostname(self, hostname: str):
        """设置hostname（用于数据分组）"""
        self.hostname = hostname
        
    async def start_monitoring(self) -> None:
        """启动Network事件监听"""
        self.connector.on_event("Network.requestWillBeSent", self._on_request_start)
        self.connector.on_event("Network.responseReceived", self._on_response_received)
        self.connector.on_event("Network.loadingFinished", self._on_request_finished)
        self.connector.on_event("Network.loadingFailed", self._on_request_failed)
    
    async def stop_monitoring(self) -> None:
        """停止Network事件监听（成对off_event）"""
        self.connector.off_event("Network.requestWillBeSent", self._on_request_start)
        self.connector.off_event("Network.responseReceived", self._on_response_received)
        self.connector.off_event("Network.loadingFinished", self._on_request_finished)
        self.connector.off_event("Network.loadingFailed", self._on_request_failed)
    
    async def _on_request_start(self, params: dict) -> None:
        """请求开始 - 纯队列路径：过滤→限速→构造元数据→入队"""
        # sessionId过滤
        if params.get("sessionId") != self.session_id:
            return
            
        # 事件频率控制
        if not self.limiter.should_process_network():
            return
            
        request_id = params["requestId"]
        
        # 构造元数据（不抓取完整body）
        request_data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "type": "network_request_start", 
            "requestId": request_id,
            "url": params["request"]["url"][:500],
            "method": params["request"]["method"],
            "headers": self._truncate_headers(params["request"]["headers"]),
            "contentLength": len(params["request"].get("postData", "")),
            "initiator": self._format_initiator_simple(params["initiator"]),
            "startTime": params["timestamp"],  # CDP原始单调时间
            "hostname": self.hostname
        }
        
        # 大请求检测
        content_length = request_data["contentLength"]
        if content_length > 1048576:  # 1MB
            request_data["largeDataAlert"] = {
                "size": content_length,
                "alert": "Large request body detected"
            }
            
            # 状态回调（非阻塞）
            if self.status_callback:
                try:
                    self.status_callback("large_request", {
                        "url": request_data["url"][:50],
                        "size_mb": content_length / (1024 * 1024),
                        "method": request_data["method"]
                    })
                except Exception as e:
                    logger.warning(f"Error in large_request status callback: {e}")
        
        # 缓存请求数据
        self.pending_requests[request_id] = request_data
        
        # 唯一出口：入队处理
        try:
            self.event_queue.put_nowait(("network_start", request_data))
        except asyncio.QueueFull:
            logger.warning("Network event queue full, dropping request start")
    
    async def _on_response_received(self, params: dict) -> None:
        """收到响应 - 更新缓存数据（仅元数据）"""
        # sessionId过滤
        if params.get("sessionId") != self.session_id:
            return
            
        request_id = params["requestId"]
        if request_id in self.pending_requests:
            response_data = {
                "responseHeaders": self._truncate_headers(params["response"]["headers"]),
                "status": params["response"]["status"], 
                "mimeType": params["response"]["mimeType"][:100],
                "responseTime": params["timestamp"]
            }
            self.pending_requests[request_id].update(response_data)
    
    async def _on_request_finished(self, params: dict) -> None:
        """请求完成 - 纯队列路径：过滤→构造→入队"""
        # sessionId过滤
        if params.get("sessionId") != self.session_id:
            return
            
        request_id = params["requestId"]
        if request_id not in self.pending_requests:
            return
            
        request_data = self.pending_requests.pop(request_id)
        
        # 大响应检测
        response_size = params.get("encodedDataLength", 0)
        if response_size > 1048576:  # >1MB响应
            request_data["largeResponseAlert"] = {
                "size": response_size,
                "alert": "Large response detected - potential 5.2MB JSON issue"
            }
            
            # 状态回调（非阻塞）
            if self.status_callback:
                try:
                    self.status_callback("large_response", {
                        "url": request_data["url"][:50],
                        "size_mb": response_size / (1024 * 1024),
                        "status": request_data.get("status", 0)
                    })
                except Exception as e:
                    logger.warning(f"Error in large_response status callback: {e}")
        
        # 更新完成信息
        request_data.update({
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "type": "network_request_complete",
            "endTime": params["timestamp"],
            "duration": params["timestamp"] - request_data["startTime"],
            "encodedDataLength": response_size
        })
        
        # 唯一出口：入队处理
        try:
            self.event_queue.put_nowait(("network_complete", request_data))
        except asyncio.QueueFull:
            logger.warning("Network event queue full, dropping request completion")
    
    async def _on_request_failed(self, params: dict) -> None:
        """请求失败 - 纯队列路径：过滤→构造→入队"""
        # sessionId过滤
        if params.get("sessionId") != self.session_id:
            return
            
        request_id = params["requestId"]
        if request_id not in self.pending_requests:
            return
            
        request_data = self.pending_requests.pop(request_id)
        request_data.update({
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "type": "network_request_failed",
            "errorText": params.get("errorText", "Unknown error")[:200],
            "canceled": params.get("canceled", False),
            "hostname": self.hostname
        })
        
        # 唯一出口：入队处理
        try:
            self.event_queue.put_nowait(("network_failed", request_data))
        except asyncio.QueueFull:
            logger.warning("Network event queue full, dropping request failure")
    
    def _truncate_headers(self, headers: dict, max_headers: int = 20, max_value_length: int = 256) -> dict:
        """截断HTTP头部：前20个键，每值≤256字符（专家建议的实现）"""
        if not headers:
            return {}
            
        truncated = {}
        count = 0
        for key, value in headers.items():
            if count >= max_headers:
                truncated["...[truncated]"] = f"{len(headers) - max_headers} more headers"
                break
                
            truncated_key = key[:100] if isinstance(key, str) else str(key)[:100]
            truncated_value = value[:max_value_length] if isinstance(value, str) else str(value)[:max_value_length]
            
            if len(str(value)) > max_value_length:
                truncated_value += "...[truncated]"
                
            truncated[truncated_key] = truncated_value
            count += 1
            
        return truncated
    
    def _format_initiator_simple(self, initiator: dict) -> dict:
        """格式化请求发起信息（简化版）"""
        result = {"type": initiator.get("type", "unknown")}
        
        if initiator.get("stack") and initiator["stack"].get("callFrames"):
            frame = initiator["stack"]["callFrames"][0]
            result["source"] = {
                "function": frame.get("functionName", "anonymous")[:100],
                "url": frame.get("url", "")[:200],
                "line": frame.get("lineNumber", 0)
            }
        
        return result
```

**4. SimpleCorrelationEngine类（完整实现 - 专家要求的时间窗关联）**
```python
import time
import logging
from collections import deque
from datetime import datetime, timezone
from typing import Optional, Callable

logger = logging.getLogger(__name__)

class SimpleCorrelationEngine:
    """简化关联分析引擎 - 时间窗口内简单规则关联（专家要求的最小实现）"""
    
    def __init__(self, status_callback: Optional[Callable] = None):
        self.status_callback = status_callback
        self.recent_events = deque(maxlen=20)  # 限制缓冲区大小
        self.correlation_window = 3.0  # ±3秒内关联检测
        
    def add_event(self, event_data: dict) -> Optional[dict]:
        """添加事件并检查时间窗口关联"""
        current_time = time.time()
        
        # 检查最近事件中的关联
        correlations = []
        for recent_event in list(self.recent_events):
            time_diff = current_time - recent_event["event_time"]
            if time_diff <= self.correlation_window:
                correlation = self._check_simple_correlation(event_data, recent_event["data"])
                if correlation:
                    correlations.append(correlation)
        
        # 添加新事件到缓冲区
        self.recent_events.append({
            "data": event_data,
            "event_time": current_time
        })
        
        # 如果发现关联，生成报告
        if correlations:
            correlation_report = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "type": "correlation",
                "hostname": event_data.get("hostname", "unknown"),
                "primary_event": {
                    "type": event_data.get("type", "unknown"),
                    "timestamp": event_data.get("timestamp", "")
                },
                "correlations": correlations[:2],  # 限制数量
                "severity": self._determine_severity(correlations),
                "evidence": "Time window correlation detected"
            }
            
            # 状态回调
            if self.status_callback:
                try:
                    self.status_callback("correlation_found", {
                        "count": len(correlations),
                        "severity": correlation_report["severity"],
                        "types": [c.get("type", "") for c in correlations]
                    })
                except Exception as e:
                    logger.warning(f"Correlation status callback error: {e}")
            
            return correlation_report
        
        return None
    
    def _check_simple_correlation(self, event1: dict, event2: dict) -> Optional[dict]:
        """检查两个事件间的简单关联规则"""
        # 规则1: 大网络响应 → 内存收集
        if (event1.get("type") == "memory" and 
            event2.get("type") in ["network_request_complete"] and
            (event2.get("largeDataAlert") or event2.get("largeResponseAlert"))):
            
            size = 0
            if event2.get("largeDataAlert"):
                size = event2["largeDataAlert"].get("size", 0)
            elif event2.get("largeResponseAlert"):
                size = event2["largeResponseAlert"].get("size", 0)
                
            return {
                "type": "large_network_to_memory",
                "network_size_mb": round(size / (1024 * 1024), 1) if size > 0 else 0,
                "evidence": "Large network data followed by memory collection"
            }
        
        # 规则2: Console错误 → 网络失败
        if (event1.get("type") in ["console", "exception"] and 
            event1.get("level") in ["error", "exception"] and
            event2.get("type") in ["network_request_failed", "network_request_complete"] and 
            (event2.get("status", 0) >= 400 or event2.get("type") == "network_request_failed")):
            
            return {
                "type": "console_error_to_network_failure",
                "network_status": event2.get("status", 0),
                "error_message": event2.get("errorText", "")[:100],
                "evidence": "Console error correlates with network failure"
            }
        
        # 规则3: 大网络响应 → Console性能标记
        if (event1.get("type") == "console" and 
            event1.get("level") == "log" and
            "time" in event1.get("message", "").lower() and
            event2.get("type") == "network_request_complete" and
            event2.get("largeResponseAlert")):
            
            return {
                "type": "performance_timing_with_large_response",
                "response_size_mb": round(event2["largeResponseAlert"].get("size", 0) / (1024 * 1024), 1),
                "evidence": "Performance timing coincides with large response processing"
            }
        
        return None
    
    def _determine_severity(self, correlations: list) -> str:
        """确定关联的严重程度"""
        if not correlations:
            return "info"
        
        # 检查关联类型
        correlation_types = [c.get("type", "") for c in correlations]
        
        # Critical: 错误相关的关联
        if "console_error_to_network_failure" in correlation_types:
            return "critical"
        
        # Warning: 大数据处理相关
        if any("large_network" in t for t in correlation_types):
            return "warning"
        
        # Info: 性能相关
        if any("performance_timing" in t for t in correlation_types):
            return "info"
        
        return "info"
```

**5. DataManager扩展和对接方案（修正版 - 专家建议的data_callback路由）**

```python
# browserfairy/data/manager.py 扩展现有类
class DataManager:  # 扩展现有类
    async def write_console_data(self, hostname: str, console_data: Dict[str, Any]) -> None:
        """Console数据写入（新增方法）"""
        if not self.running:
            return
        file_path = f"{hostname}/console.jsonl"
        await self.data_writer.append_jsonl(file_path, console_data)
    
    async def write_network_data(self, hostname: str, network_data: Dict[str, Any]) -> None:
        """Network数据写入（新增方法）"""
        if not self.running:
            return
        file_path = f"{hostname}/network.jsonl"
        await self.data_writer.append_jsonl(file_path, network_data)
    
    async def write_correlation_data(self, hostname: str, correlation_data: Dict[str, Any]) -> None:
        """关联分析数据写入（新增方法）"""
        if not self.running:
            return
        file_path = f"{hostname}/correlations.jsonl"
        await self.data_writer.append_jsonl(file_path, correlation_data)
```

**事件消费者完整实现**（专家要求的闭环通路）:

```python
# MemoryCollector._consume_events 完整实现
async def _consume_events(self):
    """事件消费者协程 - 专家要求的完整实现，确保写入通路闭环"""
    try:
        while self.running and self.enable_comprehensive:
            try:
                # 从队列获取事件（1秒超时）
                try:
                    event_type, event_data = await asyncio.wait_for(
                        self.event_queue.get(), timeout=1.0
                    )
                except asyncio.TimeoutError:
                    continue  # 无事件时继续循环
                
                # 关联分析处理
                correlation_result = None
                if self.correlation_engine:
                    correlation_result = self.correlation_engine.add_event(event_data)
                
                # 通过data_callback单一出口上抛事件
                if self.data_callback:
                    try:
                        # 发送原始事件数据
                        if asyncio.iscoroutinefunction(self.data_callback):
                            await self.data_callback(event_data)
                        else:
                            self.data_callback(event_data)
                        
                        # 发送关联结果（如有）
                        if correlation_result:
                            if asyncio.iscoroutinefunction(self.data_callback):
                                await self.data_callback(correlation_result)
                            else:
                                self.data_callback(correlation_result)
                                
                    except Exception as e:
                        logger.warning(f"Error in data_callback for {event_type}: {e}")
                        
            except Exception as e:
                logger.error(f"Error in event consumer loop: {e}")
                await asyncio.sleep(0.1)
                
    except asyncio.CancelledError:
        logger.debug("Event consumer task cancelled")
        raise
    except Exception as e:
        logger.error(f"Fatal error in event consumer: {e}")

# 上层数据路由回调（专家建议的单一写入通路）
async def comprehensive_data_callback(data: dict):
    """统一数据路由回调 - 专家要求的唯一出口，确保写入闭环"""
    hostname = data.get("hostname", "unknown")
    data_type = data.get("type", "unknown")
    
    try:
        if data_type == "memory":
            await data_manager.write_memory_data(hostname, data)
        elif data_type in ["console", "exception"]:
            await data_manager.write_console_data(hostname, data)
        elif data_type in ["network_request_complete", "network_request_failed", "network_start"]:
            await data_manager.write_network_data(hostname, data)
        elif data_type == "correlation":
            await data_manager.write_correlation_data(hostname, data)
        else:
            logger.warning(f"Unknown data type for routing: {data_type}")
            
    except Exception as e:
        logger.error(f"Error writing {data_type} data to DataManager: {e}")

# 完整使用方式（单一数据流路径）
collector = MemoryCollector(
    connector=connector,
    target_id=target_id,
    hostname=hostname,
    data_callback=comprehensive_data_callback,  # 唯一出口：事件 → data_callback → DataManager
    enable_comprehensive=True,
    status_callback=status_callback
)
```

**数据流路径**（专家要求的明确单一路径）：
```
Console/Network事件 → 过滤sessionId → 频率限制 → 构造数据 → 入队
                    ↓
                事件队列 (asyncio.Queue)
                    ↓
            事件消费者协程 (_consume_events)
                    ↓
        关联分析 (SimpleCorrelationEngine.add_event)
                    ↓
        data_callback 唯一出口 (comprehensive_data_callback)
                    ↓
        DataManager.write_*_data 方法
                    ↓
            按hostname分组的JSONL文件
```

### 修正后的实现优先级（专家评审后的必需顺序）

**Phase 1: 致命问题修正（必须首先完成，否则功能无法工作）**

**优先级1 - ChromeConnector sessionId注入修正**：
```python
# browserfairy/core/connector.py - _handle_messages方法第112-116行
params = data.get("params", {}).copy()
if "sessionId" in data:
    params["sessionId"] = data["sessionId"]
await self._dispatch_event(method, params)
```

**优先级2 - EventLimiter完整实现**：
```python
# 简单滑动窗口 + 丢弃计数 + 排障日志
# Console ≤10/s, Network ≤50/s
# 包含_update_dropped_summary方法
```

**优先级3 - ConsoleMonitor方法命名统一**：
```python
# 统一使用_extract_and_truncate_message方法（≤500字符）
# 添加set_hostname方法和hostname属性
```

**优先级4 - NetworkMonitor _truncate_headers实现**：
```python
# 前20个键，每值≤256字符（专家建议）
# CDP时间戳处理：timestamp用UTC，startTime/endTime保留原始值
```

**Phase 2: 生命周期管理修正（避免内存泄漏）**

**优先级5 - 事件消费者正确停止条件**：
```python
# while self.running and self.enable_comprehensive
# 正确处理asyncio.CancelledError
```

**优先级6 - MemoryCollector完整清理**：
```python
# stop_collection()中调用monitor.stop_monitoring()
# 取消consumer_task并await完成
# 确保不遗留任务
```

**Phase 3: 数据对接和集成测试**

**优先级7 - DataManager扩展**：
```python
# write_console_data/write_network_data/write_correlation_data方法
# comprehensive_data_callback路由函数
```

**优先级8 - 端到端验证**：
```python
# ChromeConnector修正 → sessionId过滤工作
# Console/Network事件正确捕获和队列处理
# 数据正确写入分组的JSONL文件
```

### 风险缓解措施（修正版）

**代码质量控制**：
- TDD驱动：每个修正都有对应单元测试
- 渐进集成：逐步添加功能，每步都可独立验证
- 性能基准：确保综合模式开销<2% CPU增加

**系统稳定性保证**：  
- 队列满时丢弃策略（避免内存爆炸）
- 消息长度限制（避免巨量数据）
- 事件频率控制（避免CDP消息风暴）
- 异常隔离（组件失败不影响基础内存监控）

**向后兼容性**：
- 现有MemoryCollector API保持不变
- enable_comprehensive=False时行为完全一致  
- 可以逐步从基础模式升级到综合模式

### 成功标准（现实目标）

**功能验证**：
- ✅ sessionId过滤正常工作（修正ChromeConnector后）
- ✅ Console错误能够正确捕获和回调
- ✅ 大网络请求（>1MB）能够检测和标记
- ✅ 简单时间关联能够检测（网络→内存，错误→失败）
- ✅ 数据文件按hostname正确分组（console.jsonl, network.jsonl, correlations.jsonl）

**性能指标**：
- CPU开销增加<2%（相比纯内存监控）
- 内存占用增加<15MB per tab 
- 事件处理延迟<100ms（队列批量处理）
- 事件丢失率<5%（高频场景下）

**稳定性指标**：
- 连续运行>30分钟无崩溃
- 队列满时优雅降级（丢弃而非阻塞）
- ChromeConnector修正后无sessionId过滤失效
- 异常情况下不影响基础内存收集功能

这个修正版设计解决了技术专家指出的所有致命问题，采用了推荐的最小修正方案，补全了所有缺失实现，统一了架构模式。可以安全地进入实现阶段。

### 数据输出格式

**精准问题定位报告示例**：
```json
{
    "timestamp": "2025-01-14T15:30:25.123Z",
    "type": "cross_layer_correlation", 
    "severity": "critical",
    "hostname": "trading.example.com",
    "primaryEvent": {
        "type": "network_request_complete",
        "url": "https://trading.example.com/api/risk/calculate",
        "method": "POST",
        "duration": 2333,
        "responseSize": 5242880,
        "initiator": {
            "function": "updateRiskScenarios",
            "file": "trading.js",
            "line": 245
        },
        "largeResponseAlert": {
            "responseSize": 5242880,
            "alert": "Large response detected - potential 5.2MB JSON issue"
        }
    },
    "correlations": [
        {
            "type": "network_to_memory",
            "description": "Large network response (5242880 bytes) correlates with memory spike",
            "memoryIncrease": 5242880,
            "timeDelay": 0.3
        },
        {
            "type": "network_to_console",  
            "description": "Console.time measurement during large data processing",
            "consoleMessages": [
                {"level": "log", "message": "Processing risk scenarios, data size: 5.2MB"},
                {"level": "time", "label": "JSON-parse", "duration": 1250}
            ]
        }
    ],
    "rootCauseAnalysis": {
        "identifiedFunction": "updateRiskScenarios",
        "problemCode": "trading.js:245",
        "issueType": "large_json_processing",
        "recommendation": "Consider server-side pagination or data compression"
    }
}
```

## Tests

### TDD测试设计

**1. ChromeConnector sessionId修正测试**
- 验证修正后的_handle_messages能正确注入sessionId到params
- 确认Console和Network事件的sessionId过滤正常工作

**2. EventLimiter单元测试**  
- 验证Console事件频率限制（10/s）
- 验证Network事件频率限制（50/s）
- 验证计数器每秒重置逻辑

**3. ConsoleMonitor单元测试**
- 测试console消息捕获和队列入队
- 测试JavaScript异常处理和状态回调
- 验证消息长度限制和堆栈深度限制
- 测试sessionId过滤（基于修正后的ChromeConnector）

**4. NetworkMonitor单元测试**
- 测试大请求检测（>1MB）和状态回调
- 测试大响应检测（>1MB）和关联
- 验证HTTP头部截断功能(_truncate_headers)
- 测试请求生命周期追踪（start→response→finish/fail）
- 测试sessionId过滤和事件频率控制

**5. SimpleCorrelationEngine单元测试**
- 测试时间窗口关联检测（2秒窗口）
- 验证大网络→内存关联检测
- 验证Console错误→网络失败关联
- 测试严重程度计算（critical/warning/info）
- 测试事件缓冲区限制（30个事件maxlen）

**6. MemoryCollector综合模式测试**
- 测试enable_comprehensive=True时的组件初始化
- 验证事件队列创建和消费者协程启动
- 测试hostname设置和数据分组
- 测试事件消费者的批量处理逻辑
- 验证异常隔离（comprehensive失败不影响基础内存监控）

**7. 队列架构集成测试**
- 测试asyncio.Queue的满时丢弃行为
- 验证批量事件处理（100ms窗口，50事件批次）
- 测试事件消费者的异常恢复
- 验证数据callback的异步/同步兼容性

**8. DataManager扩展测试**
- 测试console.jsonl文件写入
- 测试network.jsonl文件写入  
- 测试correlations.jsonl文件写入
- 验证按hostname分组的目录结构

**9. 性能基准测试**
- 综合模式 vs 基础模式的CPU开销对比
- 内存占用增加测试（目标<15MB per tab）
- 事件处理延迟测试（目标<100ms）
- 事件丢失率测试（高频场景下<5%）

**10. 端到端集成测试**
- 使用实际Chrome实例测试完整链路
- 模拟5.2MB JSON响应场景
- 验证Console错误→网络失败→关联检测的完整流程
- 测试多标签页并发监控（限制≤3个标签页）

### 验收测试标准

**功能验证标准**：
- ✅ sessionId过滤修正后100%工作正常
- ✅ 大请求/响应检测准确率>95%
- ✅ 时间关联检测覆盖率>80%的明显关联场景  
- ✅ 所有状态回调在50ms内响应
- ✅ 数据文件按hostname正确分组

**稳定性验证标准**：
- 连续运行30分钟无崩溃无内存泄漏
- 队列满时优雅降级（丢弃不阻塞）
- 单组件异常不影响其他组件
- ChromeConnector重连后功能正常恢复

**性能验证标准**：
- CPU开销增加<2%（相比基础内存监控）
- 内存占用增加<15MB per tab
- 事件处理延迟<100ms（P95）
- 事件丢失率<5%（1000 events/min场景）

### 修正后的性能基准（现实目标）

**综合监控开销**：
- CPU增加 <2%（相比基础内存监控）
- 内存占用增加 <15MB per tab
- 事件处理延迟 <100ms（异步队列批量处理）
- 状态回调延迟 <50ms（重要事件立即通知）

**数据效率**：
- 单网站日监控数据 <50MB（元数据级监控，无完整body）
- 事件丢失率 <5%（队列满时优雅丢弃）
- 并发标签页限制 ≤3个（受控测试，避免事件风暴）
- 关联检测精度 >80%（URL级别证据，不做函数级分析）

**稳定性指标**：
- 连续运行30分钟无崩溃
- 队列满时优雅降级（丢弃不阻塞）
- ChromeConnector重连后功能正常
- 单组件异常不影响基础内存监控

### 修正后的实现优先级（现实路径）

**Phase 1: 基础设施修正（避免阻塞问题）**
1. EventLimiter类 + 单元测试（事件频率控制）
2. 异步队列机制设计 + 测试（解决背压问题）
3. 手动sessionId过滤机制验证

**Phase 2: 核心监控组件（简化版TDD）**
1. ConsoleMonitor类（元数据级） + 单元测试
2. NetworkMonitor类（仅头部+大小） + 单元测试  
3. SimpleCorrelationEngine类（仅时间窗口） + 单元测试

**Phase 3: MemoryCollector轻量扩展**
1. 扩展MemoryCollector支持comprehensive模式（可选参数）
2. 集成异步队列和三个监控组件
3. 添加状态回调机制（为1-1-2预留）

**Phase 4: 受控验证和CLI集成**
1. 扩展DataManager支持新数据类型（console.jsonl、network.jsonl、correlations.jsonl）
2. 实现comprehensive_monitoring CLI命令（限制≤5标签页）
3. 受控环境测试（避免生产环境冲击）

**Phase 5: 渐进优化**
1. 性能基准验证和调优
2. 事件丢失率监控和改进
3. 为后续ChromeConnector session支持预留扩展点

### ⚠️ 风险控制措施
- 限制并发attach标签页数量（≤5个）
- 事件队列满时丢弃策略，避免内存爆炸
- 消息长度限制，避免巨大日志
- 频率控制，避免CDP消息风暴